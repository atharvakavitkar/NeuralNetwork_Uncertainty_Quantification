# Uncertainty in Neural Networks: Review
With the rapid adaptation of neural networks as the standard machine learning solution in various sectors of society, the question of their reliability in new and unknown environments has become increasingly relevant. Because of the tendency of neural networks to produce overconfident results in unfamiliar environments, mapping the confidence interval of a prediction from a neural network has become as important as the accuracy of its prediction itself. This paper reviews the two most prominent uncertainty quantification techniques in literature i.e. Bayesian approximation and Ensemble learning. The paper also investigates the real world application of these techniques comparing their relative performance on tasks related to robotics and computer vision (such as semantic segmentation, autonomous driving and image segmentation). In the end, the paper concludes by highlighting the challenges faced by uncertainty quantification methods and directions for future research in this field.
